import pandas as pd
import numpy as np
import os
import uuid
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression, LogisticRegression
from sklearn.metrics import r2_score, mean_absolute_error, accuracy_score, confusion_matrix, classification_report

PLOT_DIR = "static/predict_plots"
os.makedirs(PLOT_DIR, exist_ok=True)

def save_plot():
    plot_id = f"{uuid.uuid4().hex}.png"
    path = os.path.join(PLOT_DIR, plot_id)
    plt.tight_layout()
    plt.savefig(path, bbox_inches='tight')
    plt.close()
    return f"/{path}"

def run_model(model_type, data, target, features):
    df = pd.DataFrame(data)
    if not target or not isinstance(target, str) or target not in df.columns:
        return "<p>‚ùå Target column is invalid or not selected.</p>"
    df = df[features + [target]].copy()
    df = df.dropna()

    X = df[features].apply(pd.to_numeric, errors='coerce')
    y = pd.to_numeric(df[target], errors='coerce')
    df = pd.concat([X, y], axis=1).dropna()

    # ‚õî –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –∏—Å–∫–ª—é—á–µ–Ω–∏–µ —Å–ª–∞–±–æ–∫–æ—Ä—Ä–µ–ª–∏—Ä—É—é—â–∏—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    removed = []
    kept = []

    for col in features:
        if df[col].nunique() <= 1:
            removed.append(col)
            continue
        corr = np.corrcoef(df[col], y)[0, 1]
        if abs(corr) < 0.1:
            removed.append(col)
        else:
            kept.append(col)

    if not kept:
        return "<p>üö´ No features with sufficient correlation to target.</p>"

    X = df[kept]
    y = df[target]

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)

    messages = ""
    if removed:
        messages += "<p>‚ö†Ô∏è The following features were removed due to low correlation: <b>" + ", ".join(removed) + "</b></p>"

    if model_type == "linear":
        model = LinearRegression()
        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)

        r2 = r2_score(y_test, y_pred)
        mae = mean_absolute_error(y_test, y_pred)

        # –¢–µ–∫—Å—Ç–æ–≤–∞—è –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è
        if r2 < 0.3:
            interp = "Model explains very little of the target variance."
        elif r2 < 0.6:
            interp = "Model has moderate explanatory power."
        else:
            interp = "Model fits the data well."

        fig, ax = plt.subplots()
        ax.scatter(y_test, y_pred, alpha=0.6)
        ax.set_xlabel("Actual")
        ax.set_ylabel("Predicted")
        ax.set_title("Prediction vs Actual")
        plot_url = save_plot()

        return f"""
        {messages}
        <h3>üìò Linear Regression</h3>
        <p><b>R¬≤ Score:</b> {r2:.3f}</p>
        <p><b>Mean Absolute Error:</b> {mae:.3f}</p>
        <p>{interp}</p>
        <img src="{plot_url}">
        """

    elif model_type == "logistic":
        model = LogisticRegression(max_iter=1000)
        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)

        acc = accuracy_score(y_test, y_pred)

        if acc < 0.6:
            interp = "Low predictive quality."
        elif acc < 0.8:
            interp = "Acceptable accuracy."
        else:
            interp = "High accuracy ‚Äî model performs well."

        cm = confusion_matrix(y_test, y_pred)
        fig, ax = plt.subplots()
        ax.matshow(cm, cmap="Blues")
        ax.set_xlabel("Predicted")
        ax.set_ylabel("Actual")
        ax.set_title("Confusion Matrix")
        plot_url = save_plot()

        report = classification_report(y_test, y_pred)

        return f"""
        {messages}
        <h3>üìó Logistic Regression</h3>
        <p><b>Accuracy:</b> {acc:.3f}</p>
        <p>{interp}</p>
        <pre>{report}</pre>
        <img src="{plot_url}">
        """
